{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2 - Features Extraction\n",
    " Extract various features from the given data and save them to a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all the libraries needed for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas and numpy data structures to handle the data.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Importing nltk for word tokenization, sentence tokenization, \n",
    "# removing stopwords, pos taging, vocabualry richness calcuation.\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import brown\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data from the given data set, encoding in latin-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', encoding='latin-1')\n",
    "df = df.drop('Unnamed: 0',axis=1)\n",
    "df = df.drop('essay_set',1)\n",
    "essay_df = df['essay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               essay  domain1_score\n",
       "0  Dear local newspaper, I think effects computer...            6.0\n",
       "1  Dear @CAPS1 @CAPS2, I believe that using compu...            7.0\n",
       "2  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...            5.0\n",
       "3  Dear Local Newspaper, @CAPS1 I have found that...            8.0\n",
       "4  Dear @LOCATION1, I know having computers has a...            6.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tokenizing essays into sentences \n",
    "### 2. Calculating the sentence count and number of tagged words per essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the clean_essay function from the functions.py file \n",
    "# to clean the data, remove punctuations and handle the words staring with @.\n",
    "from functions import clean_essay\n",
    "\n",
    "essay_sentences_list = []\n",
    "tokenized_sentences = []\n",
    "tagged_words_count_list = []\n",
    "\n",
    "for essay in essay_df:\n",
    "    temp_list = []\n",
    "    essay_sentences_list.append(sent_tokenize(essay))\n",
    "    essay, tagged_words_count = clean_essay(essay)\n",
    "    tagged_words_count_list.append(tagged_words_count)\n",
    "    \n",
    "    for token in essay.split():\n",
    "        temp_list.append(token)\n",
    "        \n",
    "    tokenized_sentences.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of sentences in each essay.\n",
    "sentences_count = []\n",
    "\n",
    "for sentences in essay_sentences_list:\n",
    "    sentences_count.append(len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genaerating the features:\n",
    "\n",
    "#### The following features will be generated  : -\n",
    "\n",
    "All the counts are per essay - \n",
    "\n",
    "- Word count\n",
    "- Sentence count\n",
    "- Long words count( word length > 6)\n",
    "- Average word length \n",
    "- Spelling error count \n",
    "- Words to sentences ratio\n",
    "- Vocabulary richness count\n",
    "- Noun Count\n",
    "- Verb Count\n",
    "- Adverb Count\n",
    "- Adjective Count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the yule function from function.py file to calculate vocabulary richness per essay.\n",
    "from functions import yule\n",
    "\n",
    "# Storing the set of stopwords\n",
    "sw = set(stopwords.words('english'))\n",
    "\n",
    "clean_tokenized_sentences = tokenized_sentences\n",
    "\n",
    "# Store words from brown corpus to check for spelling errors.\n",
    "word_list = brown.words()\n",
    "word_set = set(word_list)\n",
    "\n",
    "word_count = []\n",
    "word_length = []\n",
    "vocab_count = []\n",
    "long_word_count = []\n",
    "average_word_length = []\n",
    "spelling_error_count = []\n",
    "word_to_sentence_ratio = []\n",
    "\n",
    "noun_count = []\n",
    "verb_count = []\n",
    "adjective_count = []\n",
    "adverb_count = []\n",
    "\n",
    "for i in range(essay_df.shape[0]):\n",
    "    word_length = []\n",
    "    long_word_counter, spelling_error_counter, domain_words_counter, wrong_word_counter  = 0, 0, 0, 0\n",
    "    \n",
    "    # Removing all the stopwords from essays.\n",
    "    clean_tokenized_sentences[i] = [word for word in clean_tokenized_sentences[i] if word not in sw]\n",
    "    \n",
    "    word_count.append(len(clean_tokenized_sentences[i]))\n",
    "    vocab_count.append(yule(clean_tokenized_sentences[i]))\n",
    "    \n",
    "    # Pos tagging all the words in the essay. \n",
    "    count = Counter([y for x,y in pos_tag(clean_tokenized_sentences[i])])\n",
    "    \n",
    "    # Saving count of various pos tags in lists\n",
    "    noun_count.append(count['NN'] + count['NNS'] + count['NNPS'] + count['NNP'])\n",
    "    verb_count.append(count['VB'] + count['VBG'] + count['VBP'] + count['VBN'] + count['VBZ'])\n",
    "    adjective_count.append(count['JJ'] + count['JJR'])\n",
    "    adverb_count.append(count['RB'] + count['RBR'] + count['RBS'])\n",
    "    \n",
    "    for word in clean_tokenized_sentences[i]:    \n",
    "        word_length.append(len(word))\n",
    "            \n",
    "        # Checking for spelling errors.\n",
    "        if word not in word_set:      \n",
    "            spelling_error_counter += 1\n",
    "        elif len(word) > 6:\n",
    "            long_word_counter += 1\n",
    "            \n",
    "    long_word_count.append(long_word_counter) \n",
    "    spelling_error_count.append(spelling_error_counter)    \n",
    "    \n",
    "    # Calculating average word length per essay.\n",
    "    average_word_length.append(round(np.sum(word_length) / float(len(word_length)), 2))\n",
    "    \n",
    "    # Calculating number of words per essay to number of sentences per essay ratio.\n",
    "    word_to_sentence_ratio.append(round(word_count[i] / float(sentences_count[i]), 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating word count by adding the tagged words which had been removed earlier.\n",
    "word_count = [sum(x) for x in zip(word_count, tagged_words_count_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing all the features in a data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(\n",
    "    {\n",
    "     'word_count': word_count,\n",
    "     'sentences_count': sentences_count,\n",
    "     'average_word_length': average_word_length,\n",
    "     'long_word_count': long_word_count,\n",
    "     'spelling_error_count': spelling_error_count,\n",
    "     'word_to_sentence_ratio': word_to_sentence_ratio,\n",
    "     'vocab_count': vocab_count,\n",
    "     'noun_count': noun_count,\n",
    "     'verb_count': verb_count,\n",
    "     'adjective_count': adjective_count,\n",
    "     'adverb_count': adverb_count\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjective_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>long_word_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>spelling_error_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>vocab_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_to_sentence_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>5.58</td>\n",
       "      <td>45</td>\n",
       "      <td>71</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>29.482659</td>\n",
       "      <td>168</td>\n",
       "      <td>10.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>5.67</td>\n",
       "      <td>62</td>\n",
       "      <td>96</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>54</td>\n",
       "      <td>20.220089</td>\n",
       "      <td>226</td>\n",
       "      <td>10.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>6.05</td>\n",
       "      <td>51</td>\n",
       "      <td>72</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>15.286432</td>\n",
       "      <td>139</td>\n",
       "      <td>9.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>13</td>\n",
       "      <td>6.23</td>\n",
       "      <td>79</td>\n",
       "      <td>123</td>\n",
       "      <td>27</td>\n",
       "      <td>41</td>\n",
       "      <td>56</td>\n",
       "      <td>30.737705</td>\n",
       "      <td>301</td>\n",
       "      <td>9.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>5.94</td>\n",
       "      <td>69</td>\n",
       "      <td>113</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>46</td>\n",
       "      <td>20.258941</td>\n",
       "      <td>226</td>\n",
       "      <td>7.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adjective_count  adverb_count  average_word_length  long_word_count  \\\n",
       "0               28            11                 5.58               45   \n",
       "1               23            10                 5.67               62   \n",
       "2               17             2                 6.05               51   \n",
       "3               41            13                 6.23               79   \n",
       "4               25            13                 5.94               69   \n",
       "\n",
       "   noun_count  sentences_count  spelling_error_count  verb_count  vocab_count  \\\n",
       "0          71               16                    16          38    29.482659   \n",
       "1          96               20                    23          54    20.220089   \n",
       "2          72               14                     4          36    15.286432   \n",
       "3         123               27                    41          56    30.737705   \n",
       "4         113               30                    20          46    20.258941   \n",
       "\n",
       "   word_count  word_to_sentence_ratio  \n",
       "0         168                   10.19  \n",
       "1         226                   10.80  \n",
       "2         139                    9.43  \n",
       "3         301                    9.63  \n",
       "4         226                    7.40  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the features\n",
    "\n",
    "Features saved in this file can directly be used for data analysis and model generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv('features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
